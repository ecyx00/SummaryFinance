import logging
from typing import List, Dict, Optional
from datetime import datetime

import newspaper
from newspaper import Article
from sqlalchemy.orm import Session

from src.db.models import News

# Logger oluÅŸtur
logger = logging.getLogger(__name__)

# Genel User-Agent tanÄ±mÄ±
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'

# Newspaper konfigÃ¼rasyonu
def get_newspaper_config() -> newspaper.Config:
    """Newspaper3k iÃ§in varsayÄ±lan konfigÃ¼rasyon oluÅŸturur."""
    config = newspaper.Config()
    config.browser_user_agent = USER_AGENT
    config.request_timeout = 10
    config.fetch_images = False
    config.memoize_articles = False
    return config


def _scrape_single_article_content(url: str, config: newspaper.Config) -> Optional[str]:
    """Tek bir URL'den haber iÃ§eriÄŸini Ã§eker.
    
    Args:
        url: Haber iÃ§eriÄŸinin Ã§ekileceÄŸi URL
        config: Newspaper3k konfigÃ¼rasyonu
        
    Returns:
        Ã‡ekilen haber metni veya None (baÅŸarÄ±sÄ±zlÄ±k durumunda)
    """
    if not url or not url.startswith(('http://', 'https://')):
        logger.warning(f"GeÃ§ersiz URL: {url}")
        return None
    
    try:
        # Article nesnesi oluÅŸtur ve indir
        article = Article(url, config=config, language='en')
        article.download()
        
        # Ä°ndirme durumunu kontrol et
        if article.download_state != 2:  # 2: Ä°ndirme baÅŸarÄ±lÄ±
            logger.warning(f"Ä°Ã§erik indirilemedi. URL: {url}, Durum: {article.download_state}")
            return None
        
        # Article.download_exception_msg kontrol et
        if hasattr(article, 'download_exception_msg') and article.download_exception_msg:
            logger.warning(f"Ä°ndirme hatasÄ±. URL: {url}, Hata: {article.download_exception_msg}")
            return None
        
        # Ä°Ã§eriÄŸi ayrÄ±ÅŸtÄ±r
        article.parse()
        
        # Ä°Ã§erik uzunluÄŸunu kontrol et
        if not article.text or len(article.text.strip()) < 150:  # Minimum 150 karakter
            logger.warning(f"Yetersiz iÃ§erik uzunluÄŸu. URL: {url}, Uzunluk: {len(article.text) if article.text else 0}")
            return None
        
        logger.info(f"Ä°Ã§erik baÅŸarÄ±yla Ã§ekildi. URL: {url}, Uzunluk: {len(article.text)}")
        return article.text
    
    except Exception as e:
        logger.error(f"Ä°Ã§erik Ã§ekme hatasÄ±. URL: {url}, Hata: {str(e)}")
        return None


def scrape_and_prepare_news_batch(news_items_from_db: List[News], newspaper_config: newspaper.Config) -> List[Dict]:
    """VeritabanÄ±ndan alÄ±nan haber listesi iÃ§in iÃ§erik Ã§eker ve analiz iÃ§in hazÄ±rlar.
    
    Args:
        news_items_from_db: VeritabanÄ±ndan alÄ±nan News nesneleri listesi
        newspaper_config: Newspaper3k konfigÃ¼rasyonu
        
    Returns:
        Ä°Ã§eriÄŸi baÅŸarÄ±yla Ã§ekilen haberlerin bilgilerini iÃ§eren sÃ¶zlÃ¼k listesi
    """
    results = []
    
    logger.info(f"Ä°ÅŸlenecek haber sayÄ±sÄ±: {len(news_items_from_db)}")
    
    for news_item in news_items_from_db:
        # Haberin URL'den iÃ§eriÄŸini Ã§ek
        content = _scrape_single_article_content(news_item.url, newspaper_config)
        
        # Ä°Ã§erik baÅŸarÄ±yla Ã§ekildiyse sonuÃ§ listesine ekle
        if content:
            # ISO formatÄ±nda tarih
            publication_date_str = news_item.publication_date.isoformat() if news_item.publication_date else None
            
            # SonuÃ§ sÃ¶zlÃ¼ÄŸÃ¼ oluÅŸtur
            result_dict = {
                "id": str(news_item.id),
                "title": news_item.title,
                "source": news_item.source,
                "publication_date": publication_date_str,
                "content": content
            }
            
            results.append(result_dict)
        else:
            logger.warning(f"Ä°Ã§erik Ã§ekilemedi, haber atlandÄ±. ID: {news_item.id}, URL: {news_item.url}")
    
    logger.info(f"BaÅŸarÄ±yla iÃ§erik Ã§ekilen haber sayÄ±sÄ±: {len(results)}")
    return results


# NLTK iÃ§in ek indirimlerin yorum satÄ±rÄ± olarak eklenmesi
"""
# Ä°lk kullanÄ±mda NLTK'nin gerekli verilerini indirmek iÃ§in:
import nltk
nltk.download('punkt')
""" 
